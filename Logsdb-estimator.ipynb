{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb47a71f",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import re \n",
    "import json\n",
    "\n",
    "\n",
    "# Elastic connection\n",
    "ELASTIC_URL = \"<cluster:port>\"\n",
    "API_KEY = \"<API Key>\"\n",
    "\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"ApiKey {API_KEY}\"\n",
    "}\n",
    "\n",
    "# function for converting the store size in integer bytes\n",
    "def size_to_bytes(size_str):\n",
    "    \"\"\"\n",
    "    Converts a data size string (e.g., '112kb', '2gb', '55mb') to bytes.\n",
    "\n",
    "    Args:\n",
    "        size_str: The data size string.\n",
    "\n",
    "    Returns:\n",
    "        The size in bytes as an integer, or 0 if the format is invalid.\n",
    "    \"\"\"\n",
    "    size_str = size_str.lower().strip()\n",
    "    \n",
    "    # Regular expression to extract the numerical value and the unit\n",
    "    match = re.match(r'^(\\d+\\.?\\d*)\\s*([kmgtp]?b?)$', size_str)\n",
    "    \n",
    "    if not match:\n",
    "        return 0\n",
    "\n",
    "    value_str, unit = match.groups()\n",
    "    value = float(value_str)\n",
    "\n",
    "    # Conversion factors (powers of 1024 for binary prefixes)\n",
    "    units = {\n",
    "        'b': 1,\n",
    "        'kb': 1024,\n",
    "        'mb': 1024**2,\n",
    "        'gb': 1024**3,\n",
    "        'tb': 1024**4,\n",
    "        'pb': 1024**5,\n",
    "    }\n",
    "    \n",
    "    # Handle cases where only the letter is provided (e.g., 'k' for 'kb')\n",
    "    if len(unit) == 1 and unit != 'b':\n",
    "        unit += 'b'\n",
    "\n",
    "    return int(value * units.get(unit, 1))\n",
    "\n",
    "# Conversion factor to logsdb\n",
    "# The settings call below retrieve 2 values , index.mode and source mode, both values are not always there: \n",
    "# conversion calculation has therefore a mixed approach\n",
    "\n",
    "def conversion_factor(index_mode):\n",
    "   lookup={\"logsdb\":1 , \"time_series\":1.0, \"standard\":0.5}\n",
    "   \n",
    "   return lookup.get(index_mode,1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20888a0d",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "# Get a list of nodes \n",
    "api_url = ELASTIC_URL+\"/_cat/nodes?format=json\"\n",
    "response = requests.get(api_url, headers=headers)\n",
    "response.raise_for_status()\n",
    "\n",
    "nodes_json = response.json()\n",
    "df_nodes = pd.DataFrame(nodes_json)\n",
    "\n",
    "#add note.type column\n",
    "df_nodes[\"node.type\"]=\"\"\n",
    "\n",
    "#Calculate node type\n",
    "for i in range(len(df_nodes)):\n",
    "  target_row=df_nodes.index[i]\n",
    "  # filtering for only hot,warm and cold nodes ! Adjust if you want to take along frozen nodes !!\n",
    "  df_nodes.at[target_row,'node.type']=re.sub(\"d|f|i|l|m|r|s|t|v|\\-\",\"\",df_nodes.at[target_row,'node.role'])\n",
    "\n",
    "df_hwc=df_nodes[['name','node.role','node.type']]\n",
    "\n",
    "mask=df_hwc['node.type']!=''\n",
    "df_hwc=df_hwc[mask]\n",
    "df_hwc=df_hwc.rename(columns={'name':'node'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "811c856f",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "# Get a list of shards\n",
    "api_url = ELASTIC_URL + \"/_cat/shards?format=json\"\n",
    "response = requests.get(api_url, headers=headers)\n",
    "response.raise_for_status()\n",
    "\n",
    "shards_json = response.json()\n",
    "df_shards = pd.DataFrame(shards_json)\n",
    "# Filter for data streams (.ds* indices) only !!!\n",
    "mask = (df_shards['index'].str.contains('.ds')) & (df_shards['docs'].astype(int) > 0)\n",
    "df_ds = df_shards[mask].copy() \n",
    "df_ds['store_bytes'] = df_ds['store'].astype(str).apply(size_to_bytes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a2201c9",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "# Get Settings\n",
    "\n",
    "api_url = ELASTIC_URL + \"/_settings/?include_defaults&filter_path=*.settings.index.*\"\n",
    "response = requests.get(api_url, headers=headers)\n",
    "response.raise_for_status()\n",
    "\n",
    "response_json = response.json()\n",
    "df_settings=pd.DataFrame(columns=['index','index.mode'])\n",
    "\n",
    "for key in response_json:\n",
    "    index_mode = response_json[key].get('settings', {}).get('index', {}).get('mode', 'standard')\n",
    "    \n",
    "    df_settings.loc[len(df_settings)] = [key, index_mode]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc1e24bb",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "# Merge the nodes, shards , and settings dataframes to one , and calculate per shard the impact of a conversion\n",
    "\n",
    "df_merged = pd.merge(pd.merge(df_hwc, df_ds, on='node', how='inner'), df_settings, on='index', how='inner')\n",
    "df_merged['store_optimised'] = [\n",
    "\tconversion_factor(str(row['index.mode']))\n",
    "\t* row['store_bytes']\n",
    "\tfor _, row in df_merged.iterrows()\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90a0976d",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "('node', 'node.type')",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Instance",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Tier",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Current Volume (gb)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Est. Volume (gb)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "% Change",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "693a19ca-e308-4109-8af7-193ebe2a4277",
       "rows": [
        [
         "('instance-0000000000', 'h')",
         "instance-0000000000",
         "h",
         "452.0",
         "447.0",
         "1.0"
        ],
        [
         "('instance-0000000003', 'h')",
         "instance-0000000003",
         "h",
         "452.0",
         "447.0",
         "1.0"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Instance</th>\n",
       "      <th>Tier</th>\n",
       "      <th>Current Volume (gb)</th>\n",
       "      <th>Est. Volume (gb)</th>\n",
       "      <th>% Change</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>node</th>\n",
       "      <th>node.type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>instance-0000000000</th>\n",
       "      <th>h</th>\n",
       "      <td>instance-0000000000</td>\n",
       "      <td>h</td>\n",
       "      <td>452.0</td>\n",
       "      <td>447.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instance-0000000003</th>\n",
       "      <th>h</th>\n",
       "      <td>instance-0000000003</td>\n",
       "      <td>h</td>\n",
       "      <td>452.0</td>\n",
       "      <td>447.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Instance Tier  Current Volume (gb)  \\\n",
       "node                node.type                                                  \n",
       "instance-0000000000 h          instance-0000000000    h                452.0   \n",
       "instance-0000000003 h          instance-0000000003    h                452.0   \n",
       "\n",
       "                               Est. Volume (gb)  % Change  \n",
       "node                node.type                              \n",
       "instance-0000000000 h                     447.0       1.0  \n",
       "instance-0000000003 h                     447.0       1.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# aggregate per instance store size and optimised size, calculate percentual benefit and convert values to a friendly format\n",
    "agg_dict={\n",
    "    'node' :'max',\n",
    "    'node.type' : 'max',\n",
    "    'store_bytes': 'sum',\n",
    "    'store_optimised': 'sum'\n",
    "}\n",
    "df_summary=df_merged.groupby(['node','node.type']).agg(agg_dict)\n",
    "\n",
    "df_summary['perc']=round((df_summary['store_bytes']- df_summary['store_optimised'])/df_summary['store_bytes']*100,1)\n",
    "df_summary['store_gb']=round(df_summary['store_bytes']/1024/1024)\n",
    "df_summary['optimised_gb']=round(df_summary['store_optimised']/1024/1024)\n",
    "\n",
    "# Display result\n",
    "\n",
    "output_table = df_summary[['node', 'node.type','store_gb','optimised_gb','perc']].rename(columns={\n",
    "    'node': 'Instance',\n",
    "     'node.type': 'Tier',\n",
    "     'store_gb' : 'Current Volume (gb)',\n",
    "     'optimised_gb': 'Est. Volume (gb)',\n",
    "     'perc' : '% Change'\n",
    "     })\n",
    "\n",
    "display(output_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
