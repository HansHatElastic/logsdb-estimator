{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb47a71f",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import re \n",
    "import json\n",
    "\n",
    "#switch off warnings\n",
    "\n",
    "# Elastic connection\n",
    "ELASTIC_URL = \"https://29eacf86e40847c88adfd21fbd236e65.us-east-2.aws.elastic-cloud.com:443\"\n",
    "API_KEY = \"YkhvNHBwY0JDWmdteGdUMjUtMzk6WjhUdzcyYWFvSUVyRDBZSGEzWlMyZw==\"\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"ApiKey {API_KEY}\"\n",
    "}\n",
    "\n",
    "# function for converting the store size in integer bytes\n",
    "def size_to_bytes(size_str):\n",
    "    \"\"\"\n",
    "    Converts a data size string (e.g., '112kb', '2gb', '55mb') to bytes.\n",
    "\n",
    "    Args:\n",
    "        size_str: The data size string.\n",
    "\n",
    "    Returns:\n",
    "        The size in bytes as an integer, or 0 if the format is invalid.\n",
    "    \"\"\"\n",
    "    size_str = size_str.lower().strip()\n",
    "    \n",
    "    # Regular expression to extract the numerical value and the unit\n",
    "    match = re.match(r'^(\\d+\\.?\\d*)\\s*([kmgtp]?b?)$', size_str)\n",
    "    \n",
    "    if not match:\n",
    "        return 0\n",
    "\n",
    "    value_str, unit = match.groups()\n",
    "    value = float(value_str)\n",
    "\n",
    "    # Conversion factors (powers of 1024 for binary prefixes)\n",
    "    units = {\n",
    "        'b': 1,\n",
    "        'kb': 1024,\n",
    "        'mb': 1024**2,\n",
    "        'gb': 1024**3,\n",
    "        'tb': 1024**4,\n",
    "        'pb': 1024**5,\n",
    "    }\n",
    "    \n",
    "    # Handle cases where only the letter is provided (e.g., 'k' for 'kb')\n",
    "    if len(unit) == 1 and unit != 'b':\n",
    "        unit += 'b'\n",
    "\n",
    "    return int(value * units.get(unit, 1))\n",
    "\n",
    "# Conversion factor to logsdb\n",
    "# The settings call below retrieve 2 values , index.mode and source mode, both values are not always there: \n",
    "# conversion calculation has therefore a mixed approach\n",
    "\n",
    "def conversion_factor(index_mode,source_mode):\n",
    "   lookup1={\"logsdb\":1 , \"time_series\":1.0, \"normal\":0.5}\n",
    "   lookup2={\"SYNTHETIC\":1, \"STORED\":0.5}\n",
    "   return min(lookup1.get(index_mode,1),lookup2.get(source_mode,1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20888a0d",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "# Get a list of nodes \n",
    "api_url = ELASTIC_URL+\"/_cat/nodes?format=json\"\n",
    "response = requests.get(api_url, headers=headers)\n",
    "response.raise_for_status()\n",
    "\n",
    "nodes_json = response.json()\n",
    "df_nodes = pd.DataFrame(nodes_json)\n",
    "\n",
    "#add note.type column\n",
    "df_nodes[\"node.type\"]=\"\"\n",
    "\n",
    "#Calculate node type\n",
    "for i in range(len(df_nodes)):\n",
    "  target_row=df_nodes.index[i]\n",
    "  # filtering for only hot,warm and cold nodes ! Adjust if you want to take along frozen nodes !!\n",
    "  df_nodes.at[target_row,'node.type']=re.sub(\"d|f|i|l|m|r|s|t|v|\\-\",\"\",df_nodes.at[target_row,'node.role'])\n",
    "\n",
    "df_hwc=df_nodes[['name','node.role','node.type']]\n",
    "\n",
    "mask=df_hwc['node.type']!=''\n",
    "df_hwc=df_hwc[mask]\n",
    "df_hwc=df_hwc.rename(columns={'name':'node'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811c856f",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "# Get a list of shards\n",
    "api_url = ELASTIC_URL + \"/_cat/shards?format=json\"\n",
    "response = requests.get(api_url, headers=headers)\n",
    "response.raise_for_status()\n",
    "\n",
    "shards_json = response.json()\n",
    "df_shards = pd.DataFrame(shards_json)\n",
    "# Filter for data streams (.ds* indices) only !!!\n",
    "mask = (df_shards['index'].str.contains('.ds')) & (df_shards['docs'].astype(int) > 0)\n",
    "df_ds = df_shards[mask].copy() \n",
    "df_ds['store_bytes'] = df_ds['store'].astype(str).apply(size_to_bytes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2201c9",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "# Get Settings\n",
    "\n",
    "api_url = ELASTIC_URL + \"/_settings/?include_defaults&filter_path=*.settings.index.mode,*.defaults.index.mapping.source.mode\"\n",
    "response = requests.get(api_url, headers=headers)\n",
    "response.raise_for_status()\n",
    "\n",
    "response_json = response.json()\n",
    "df_settings=pd.DataFrame(columns=['index','index.mode','source.mode'])\n",
    "\n",
    "for key in response_json:\n",
    "    index_mode= None\n",
    "    if 'settings' in response_json[key]:\n",
    "        index_mode = response_json[key].get('settings', {}).get('index', {}).get('mode', None)\n",
    "    source_mode = None\n",
    "    if 'defaults' in response_json[key]:\n",
    "        source_mode = response_json[key]['defaults'].get('index', {}).get('mapping', {}).get('source', {}).get('mode', None)\n",
    "    df_settings.loc[len(df_settings)] = [key, index_mode, source_mode]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1e24bb",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "# Merge the nodes, shards , and settings dataframes to one , and calculate per shard the impact of a conversion\n",
    "\n",
    "df_merged = pd.merge(pd.merge(df_hwc, df_ds, on='node', how='inner'), df_settings, on='index', how='inner')\n",
    "df_merged['store_optimised'] = [\n",
    "\tconversion_factor(str(row['index.mode']), str(row['source.mode']))\n",
    "\t* row['store_bytes']\n",
    "\tfor _, row in df_merged.iterrows()\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a0976d",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "# aggredate per instance store size and optimised size, calculate percentual benefit and convert values to a friendly format\n",
    "agg_dict={\n",
    "    'store_bytes': 'sum',\n",
    "    'store_optimised': 'sum'\n",
    "}\n",
    "df_summary=df_merged.groupby(['node','node.type']).agg(agg_dict)\n",
    "\n",
    "df_summary['Perc']=round((df_summary['store_bytes']- df_summary['store_optimised'])/df_summary['store_bytes']*100,1)\n",
    "df_summary['store_GB']=round(df_summary['store_bytes']/1024/1024)\n",
    "df_summary['optimised_GB']=round(df_summary['store_optimised']/1024/1024)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
